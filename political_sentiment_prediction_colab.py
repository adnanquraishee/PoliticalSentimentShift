"""
Political Sentiment Shift Prediction using Neural Networks and Time-Series Forecasting
Optimized for Google Colab
A comprehensive data science project for analyzing political sentiment trends
"""

# ============================================================================
# STEP 1: Import all required libraries
# ============================================================================
print("="*80)
print("STEP 1: Installing and Importing Required Libraries")
print("="*80)

# Install required packages in Colab
# !pip install transformers torch torchvision torchaudio --quiet
# !pip install gradio --quiet
# !pip install nltk --quiet

import warnings
warnings.filterwarnings('ignore')

# Data manipulation and analysis
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import io
import os
import pickle
import json

# Visualization
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Text preprocessing
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

# Machine Learning - Scikit-learn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (accuracy_score, f1_score, confusion_matrix, 
                             classification_report, mean_absolute_error, 
                             precision_recall_fscore_support, roc_curve, auc)

# Deep Learning - PyTorch
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset

# Transformers for sentiment analysis
from transformers import (AutoTokenizer, AutoModelForSequenceClassification,
                         pipeline)

# Gradio for deployment
import gradio as gr

# Download NLTK resources
print("\nDownloading NLTK resources...")
nltk.download('punkt', quiet=True)
nltk.download('punkt_tab', quiet=True)
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('omw-1.4', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)

print("\nâœ“ All libraries imported successfully!")
print("="*80)


# ============================================================================
# STEP 2: Read the dataset
# ============================================================================
print("\n" + "="*80)
print("STEP 2: Reading the Dataset")
print("="*80)

def create_sample_dataset():
    """Create sample political news dataset from provided data"""
    
    data = {
        'author': [
            'The Quint', 'The Quint', 'The Quint', 'The Quint', 'The Quint',
            'Pushpesh Pant', 'Pushpesh Pant', 'Pushpesh Pant', 'Pushpesh Pant',
            'Meeran Chadha Borwankar', 'Meeran Chadha Borwankar', 'Meeran Chadha Borwankar',
            'Mayukh Ghosh', 'Mayukh Ghosh', 'Akanksha Kumar', 'Akanksha Kumar',
            'The Quint', 'Pushpesh Pant', 'Meeran Chadha Borwankar', 'Mayukh Ghosh'
        ],
        'content': [
            'Tulsi Gabbard considering run for American presidency in 2020. Democrat lawmaker from Hawaii receives standing ovation.',
            'Gabbard broke with Democratic Party establishment and endorsed Bernie Sanders instead of Hillary Clinton in 2016.',
            'Critics question Gabbards views on foreign policy and tolerance of dictators like Syrian leader Bashar al-Assad.',
            'Gabbard was one of few to criticise US governments decision to deny visa to Narendra Modi after Gujarat riots.',
            'Gabbard opposed resolution calling for religious freedom in United States-India Strategic Dialogue.',
            'Swami Vivekananda ranks among highest in pantheon of distinguished children of Mother India. His charismatic personality electrified audiences.',
            'Vivekananda was arguably the first and most successful brand ambassador of resurgent India in USA.',
            'Congress and opposition parties desperately trying to get foothold in hearts and minds of voters who proclaim adherence to Sanatana Dharma.',
            'Strategists working overtime on marketing Soft Hinduism to counter machinations of Hindutva Brigade.',
            'Central Bureau of Investigation attracting public attention for misdemeanor of past directors and alleged discord.',
            'Criminal cases against former CBI directors Ranjit Sinha and AP Singh cast shadow over bureau.',
            'High-powered panel for selection of CBI director includes Prime Minister, Leader of Opposition, Chief Justice of India.',
            'Mrinal Sen started shouting out his own politics with cult-classic at time when Naxalite movement was at peak.',
            'Sen developed new language for Indian filmmakers giving birth to Indian New Wave influenced by French New Wave.',
            'Former Delhi Police Joint Commissioner recalls leading probe into murder of Naina Sahni that shocked entire country.',
            'Sushil Sharma former Youth Congress leader shot wife dead and tried to burn body. Supreme Court commuted death sentence.',
            'Political tensions rise as election campaign intensifies across major states with fierce debates.',
            'Religious freedom and tolerance remain critical issues in current political discourse and policy making.',
            'Government institutions face credibility crisis amid allegations of political interference and corruption.',
            'Cultural and artistic movements continue to reflect and shape sociopolitical consciousness of nation.'
        ],
        'date': [
            '2018-11-13', '2018-11-10', '2018-11-08', '2018-11-05', '2018-11-02',
            '2018-07-03', '2018-07-05', '2018-07-08', '2018-07-10',
            '2018-07-18', '2018-07-20', '2018-07-22',
            '2018-05-14', '2018-05-16',
            '2018-04-30', '2018-05-02',
            '2018-10-28', '2018-06-30', '2018-07-25', '2018-05-20'
        ],
        'tag': [
            'Tulsi Gabbard', 'Democratic Party', 'Foreign Policy', 'India Relations', 'Religious Freedom',
            'Swami Vivekananda', 'Hinduism', 'Politics of religion', 'Hindu Monks',
            'Modi Government', 'Central Bureau of Investigation', 'Indian Police Service',
            'Political Satire', 'Indian New Wave',
            'Supreme Court of India', 'Life Imprisonment',
            'Elections', 'Religious Tolerance', 'Government Corruption', 'Political Cinema'
        ],
        'title': [
            'Tulsi Gabbard May Run for Presidency',
            'Gabbard Endorses Bernie Sanders',
            'Foreign Policy Views Questioned',
            'Modi Visa Criticism',
            'Religious Freedom Resolution',
            'Vivekananda Birth Anniversary',
            'Brand Ambassador of India',
            'Soft Hinduism Strategy',
            'Political Strategy Shift',
            'CBI Controversy',
            'Directors Tainted Cases',
            'Selection Procedure Issues',
            'Mrinal Sen Political Cinema',
            'Indian New Wave Birth',
            'Tandoor Murder Case',
            'Death Sentence Commuted',
            'Election Campaign Heats Up',
            'Religious Discourse',
            'Institutional Crisis',
            'Cultural Movements'
        ],
        'url': [
            'https://www.thequint.com/news/1', 'https://www.thequint.com/news/2',
            'https://www.thequint.com/news/3', 'https://www.thequint.com/news/4',
            'https://www.thequint.com/news/5', 'https://www.thequint.com/voices/1',
            'https://www.thequint.com/voices/2', 'https://www.thequint.com/voices/3',
            'https://www.thequint.com/voices/4', 'https://www.thequint.com/voices/5',
            'https://www.thequint.com/voices/6', 'https://www.thequint.com/voices/7',
            'https://www.thequint.com/entertainment/1', 'https://www.thequint.com/entertainment/2',
            'https://www.thequint.com/videos/1', 'https://www.thequint.com/videos/2',
            'https://www.thequint.com/news/6', 'https://www.thequint.com/voices/8',
            'https://www.thequint.com/voices/9', 'https://www.thequint.com/entertainment/3'
        ],
        'website': ['quint'] * 20
    }
    
    df = pd.DataFrame(data)
    return df

# Load the dataset
df = create_sample_dataset()

print(f"\nâœ“ Dataset loaded successfully!")
print(f"Dataset shape: {df.shape}")
print(f"Columns: {list(df.columns)}")


# ============================================================================
# STEP 3: Explore the data
# ============================================================================
print("\n" + "="*80)
print("STEP 3: Data Exploration")
print("="*80)

print("\n--- First 5 rows ---")
print(df.head())

print("\n--- Last 5 rows ---")
print(df.tail())

print("\n--- Random 3 samples ---")
print(df.sample(3))

print(f"\n--- Dataset Shape ---")
print(f"Rows: {df.shape[0]}, Columns: {df.shape[1]}")

print(f"\n--- Column Names ---")
print(df.columns.tolist())

print(f"\n--- Data Types ---")
print(df.dtypes)

print(f"\n--- Dataset Info ---")
df.info()

print(f"\n--- Statistical Description ---")
print(df.describe(include='all'))

print(f"\n--- Content Length Statistics ---")
df['content_length'] = df['content'].str.len()
print(df['content_length'].describe())


# ============================================================================
# STEP 4: Check duplicate data, missing values, outliers
# ============================================================================
print("\n" + "="*80)
print("STEP 4: Data Quality Checks")
print("="*80)

# Check duplicates
print(f"\n--- Duplicate Records ---")
duplicate_count = df.duplicated().sum()
print(f"Number of duplicate rows: {duplicate_count}")
if duplicate_count > 0:
    df = df.drop_duplicates()
    print(f"âœ“ Duplicates removed. New shape: {df.shape}")

# Check missing values
print(f"\n--- Missing Values ---")
missing_values = df.isnull().sum()
print(missing_values)
missing_percentage = (df.isnull().sum() / len(df)) * 100
print(f"\n--- Missing Values Percentage ---")
print(missing_percentage)

# Handle missing values
if df.isnull().sum().sum() > 0:
    print("\nâœ“ Filling missing values...")
    df['content'].fillna('', inplace=True)
    df['title'].fillna('Untitled', inplace=True)
    df['tag'].fillna('General', inplace=True)

# Check outliers in content length
print(f"\n--- Outliers in Content Length ---")
Q1 = df['content_length'].quantile(0.25)
Q3 = df['content_length'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
outliers = df[(df['content_length'] < lower_bound) | (df['content_length'] > upper_bound)]
print(f"Number of outliers: {len(outliers)}")
print(f"Content length range: {df['content_length'].min()} - {df['content_length'].max()}")

# Visualize content length distribution
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.hist(df['content_length'], bins=20, color='skyblue', edgecolor='black')
plt.xlabel('Content Length')
plt.ylabel('Frequency')
plt.title('Distribution of Content Length')
plt.axvline(df['content_length'].mean(), color='red', linestyle='--', label=f'Mean: {df["content_length"].mean():.0f}')
plt.legend()

plt.subplot(1, 2, 2)
plt.boxplot(df['content_length'])
plt.ylabel('Content Length')
plt.title('Boxplot of Content Length')
plt.tight_layout()
plt.savefig('content_length_analysis.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"\nâœ“ Data quality checks completed!")


# ============================================================================
# STEP 5: Perform text preprocessing
# ============================================================================
print("\n" + "="*80)
print("STEP 5: Text Preprocessing")
print("="*80)

class TextPreprocessor:
    def __init__(self):
        self.stop_words = set(stopwords.words('english'))
        self.lemmatizer = WordNetLemmatizer()
        
    def clean_text(self, text):
        """Clean and preprocess text"""
        # Convert to lowercase
        text = text.lower()
        
        # Remove URLs
        text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
        
        # Remove special characters and digits
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        
        # Remove extra whitespaces
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def tokenize(self, text):
        """Tokenize text"""
        return word_tokenize(text)
    
    def remove_stopwords(self, tokens):
        """Remove stopwords"""
        return [word for word in tokens if word not in self.stop_words and len(word) > 2]
    
    def lemmatize(self, tokens):
        """Lemmatize tokens"""
        return [self.lemmatizer.lemmatize(word) for word in tokens]
    
    def preprocess(self, text):
        """Complete preprocessing pipeline"""
        # Clean text
        text = self.clean_text(text)
        
        # Tokenize
        tokens = self.tokenize(text)
        
        # Remove stopwords
        tokens = self.remove_stopwords(tokens)
        
        # Lemmatize
        tokens = self.lemmatize(tokens)
        
        # Join back to string
        return ' '.join(tokens)

# Initialize preprocessor
preprocessor = TextPreprocessor()

# Apply preprocessing
print("\nPreprocessing text data...")
df['processed_content'] = df['content'].apply(preprocessor.preprocess)
df['processed_title'] = df['title'].apply(preprocessor.preprocess)

print("\n--- Before and After Preprocessing Examples ---")
for i in range(3):
    print(f"\n{i+1}. Original: {df['content'].iloc[i][:100]}...")
    print(f"   Processed: {df['processed_content'].iloc[i][:100]}...")

print(f"\nâœ“ Text preprocessing completed!")


# ============================================================================
# STEP 6: Generate sentiment scores using pretrained transformer model
# ============================================================================
print("\n" + "="*80)
print("STEP 6: Sentiment Analysis using Transformer Model")
print("="*80)

print("\nLoading DistilBERT sentiment analysis model...")
# Initialize sentiment analysis pipeline
sentiment_analyzer = pipeline(
    "sentiment-analysis",
    model="distilbert-base-uncased-finetuned-sst-2-english",
    device=0 if torch.cuda.is_available() else -1
)

def get_sentiment_score(text):
    """Get sentiment score from text"""
    try:
        # Truncate text if too long (max 512 tokens for BERT)
        text = text[:512]
        result = sentiment_analyzer(text)[0]
        
        # Convert to numeric score: POSITIVE -> positive, NEGATIVE -> negative
        if result['label'] == 'POSITIVE':
            return result['score']
        else:
            return -result['score']
    except:
        return 0.0

print("\nAnalyzing sentiment for all articles...")
df['sentiment_score'] = df['content'].apply(get_sentiment_score)
df['title_sentiment'] = df['title'].apply(get_sentiment_score)

# Combined sentiment (weighted average)
df['combined_sentiment'] = 0.7 * df['sentiment_score'] + 0.3 * df['title_sentiment']

print("\n--- Sentiment Statistics ---")
print(df[['sentiment_score', 'title_sentiment', 'combined_sentiment']].describe())

# Visualize sentiment distribution
plt.figure(figsize=(14, 5))

plt.subplot(1, 3, 1)
plt.hist(df['sentiment_score'], bins=15, color='lightcoral', edgecolor='black', alpha=0.7)
plt.xlabel('Sentiment Score')
plt.ylabel('Frequency')
plt.title('Content Sentiment Distribution')
plt.axvline(0, color='red', linestyle='--', linewidth=2)

plt.subplot(1, 3, 2)
plt.hist(df['title_sentiment'], bins=15, color='lightgreen', edgecolor='black', alpha=0.7)
plt.xlabel('Sentiment Score')
plt.ylabel('Frequency')
plt.title('Title Sentiment Distribution')
plt.axvline(0, color='red', linestyle='--', linewidth=2)

plt.subplot(1, 3, 3)
plt.hist(df['combined_sentiment'], bins=15, color='skyblue', edgecolor='black', alpha=0.7)
plt.xlabel('Combined Sentiment Score')
plt.ylabel('Frequency')
plt.title('Combined Sentiment Distribution')
plt.axvline(0, color='red', linestyle='--', linewidth=2)

plt.tight_layout()
plt.savefig('sentiment_distribution.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"\nâœ“ Sentiment analysis completed!")


# ============================================================================
# STEP 7: Aggregate sentiment scores by date to create time-series dataset
# ============================================================================
print("\n" + "="*80)
print("STEP 7: Creating Time-Series Dataset")
print("="*80)

# Convert date to datetime
df['date'] = pd.to_datetime(df['date'])
df = df.sort_values('date')

# Aggregate by date
print("\nAggregating sentiment scores by date...")
time_series_df = df.groupby('date').agg({
    'sentiment_score': ['mean', 'std', 'min', 'max', 'count'],
    'combined_sentiment': ['mean', 'std'],
    'content_length': 'mean'
}).reset_index()

# Flatten column names
time_series_df.columns = ['date', 'sentiment_mean', 'sentiment_std', 'sentiment_min', 
                          'sentiment_max', 'article_count', 'combined_sentiment_mean', 
                          'combined_sentiment_std', 'avg_content_length']

# Fill missing dates and interpolate
date_range = pd.date_range(start=time_series_df['date'].min(), 
                           end=time_series_df['date'].max(), 
                           freq='D')
time_series_df = time_series_df.set_index('date').reindex(date_range)
time_series_df = time_series_df.interpolate(method='linear').bfill().ffill()
time_series_df = time_series_df.reset_index().rename(columns={'index': 'date'})

print(f"\nTime-series dataset shape: {time_series_df.shape}")
print("\n--- Time-series Data Preview ---")
print(time_series_df.head(10))

# Visualize time-series
plt.figure(figsize=(15, 6))

plt.subplot(2, 1, 1)
plt.plot(time_series_df['date'], time_series_df['sentiment_mean'], 
         marker='o', linewidth=2, markersize=4, label='Mean Sentiment')
plt.fill_between(time_series_df['date'], 
                 time_series_df['sentiment_mean'] - time_series_df['sentiment_std'],
                 time_series_df['sentiment_mean'] + time_series_df['sentiment_std'],
                 alpha=0.3, label='Â±1 Std Dev')
plt.xlabel('Date')
plt.ylabel('Sentiment Score')
plt.title('Political Sentiment Over Time')
plt.legend()
plt.grid(True, alpha=0.3)
plt.axhline(0, color='red', linestyle='--', linewidth=1)

plt.subplot(2, 1, 2)
plt.plot(time_series_df['date'], time_series_df['combined_sentiment_mean'], 
         marker='s', linewidth=2, markersize=4, color='green', label='Combined Sentiment')
plt.xlabel('Date')
plt.ylabel('Combined Sentiment Score')
plt.title('Combined Sentiment Trend')
plt.legend()
plt.grid(True, alpha=0.3)
plt.axhline(0, color='red', linestyle='--', linewidth=1)

plt.tight_layout()
plt.savefig('time_series_sentiment.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"\nâœ“ Time-series dataset created!")


# ============================================================================
# STEP 8: Create shift labels based on future sentiment difference
# ============================================================================
print("\n" + "="*80)
print("STEP 8: Creating Sentiment Shift Labels")
print("="*80)

def create_shift_labels(df, forecast_horizon=3, threshold=0.1):
    """
    Create shift labels based on future sentiment changes
    
    Parameters:
    - forecast_horizon: Number of days to look ahead
    - threshold: Minimum change to consider as shift
    """
    df = df.copy()
    
    # Calculate future sentiment
    df['future_sentiment'] = df['sentiment_mean'].shift(-forecast_horizon)
    
    # Calculate sentiment change
    df['sentiment_change'] = df['future_sentiment'] - df['sentiment_mean']
    
    # Create shift labels
    def classify_shift(change):
        if pd.isna(change):
            return 'stable'
        elif change > threshold:
            return 'positive_shift'
        elif change < -threshold:
            return 'negative_shift'
        else:
            return 'stable'
    
    df['shift_label'] = df['sentiment_change'].apply(classify_shift)
    
    # Remove rows with NaN in future_sentiment
    df = df.dropna(subset=['future_sentiment'])
    
    return df

# Create shift labels
time_series_df = create_shift_labels(time_series_df, forecast_horizon=3, threshold=0.05)

print("\n--- Shift Label Distribution ---")
print(time_series_df['shift_label'].value_counts())
print("\n--- Shift Label Percentages ---")
print(time_series_df['shift_label'].value_counts(normalize=True) * 100)

# Visualize shift labels
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
time_series_df['shift_label'].value_counts().plot(kind='bar', color=['green', 'gray', 'red'])
plt.xlabel('Shift Type')
plt.ylabel('Count')
plt.title('Distribution of Sentiment Shift Labels')
plt.xticks(rotation=45)

plt.subplot(1, 2, 2)
colors = {'positive_shift': 'green', 'stable': 'gray', 'negative_shift': 'red'}
for label in time_series_df['shift_label'].unique():
    mask = time_series_df['shift_label'] == label
    plt.scatter(time_series_df[mask]['date'], 
               time_series_df[mask]['sentiment_mean'],
               c=colors.get(label, 'blue'), 
               label=label, 
               alpha=0.6, 
               s=100)
plt.xlabel('Date')
plt.ylabel('Sentiment Score')
plt.title('Sentiment Scores by Shift Label')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('shift_labels.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"\nâœ“ Shift labels created!")


# ============================================================================
# STEP 9: Perform input-output split
# ============================================================================
print("\n" + "="*80)
print("STEP 9: Input-Output Split")
print("="*80)

# Define features and target
feature_columns = ['sentiment_mean', 'sentiment_std', 'sentiment_min', 
                  'sentiment_max', 'combined_sentiment_mean', 
                  'combined_sentiment_std', 'avg_content_length']

# Create sequences for time-series prediction
def create_sequences(data, features, target, sequence_length=7):
    """
    Create sequences for LSTM/GRU input
    
    Parameters:
    - sequence_length: Number of time steps to look back
    """
    X, y = [], []
    
    for i in range(len(data) - sequence_length):
        X.append(data[features].iloc[i:i+sequence_length].values)
        y.append(data[target].iloc[i+sequence_length])
    
    return np.array(X), np.array(y)

# Clean time_series_df to remove any remaining NaNs
time_series_df = time_series_df.fillna(0)
time_series_df = time_series_df.replace([np.inf, -np.inf], 0)

# Encode labels
label_encoder = LabelEncoder()
time_series_df['shift_label_encoded'] = label_encoder.fit_transform(time_series_df['shift_label'])

print(f"\nLabel encoding: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}")

# Create sequences
SEQUENCE_LENGTH = 5
X, y = create_sequences(time_series_df, feature_columns, 'shift_label_encoded', SEQUENCE_LENGTH)
X = np.nan_to_num(X)

print(f"\nSequence dataset created:")
print(f"X shape: {X.shape} (samples, time_steps, features)")
print(f"y shape: {y.shape} (samples,)")
print(f"Number of classes: {len(np.unique(y))}")

print(f"\nâœ“ Input-output split completed!")


# ============================================================================
# STEP 10: Perform train-test split
# ============================================================================
print("\n" + "="*80)
print("STEP 10: Train-Test Split")
print("="*80)

# Split data (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTrain set: X_train shape = {X_train.shape}, y_train shape = {y_train.shape}")
print(f"Test set: X_test shape = {X_test.shape}, y_test shape = {y_test.shape}")

# Normalize features
scaler = StandardScaler()
X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])
X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])

X_train_scaled = scaler.fit_transform(X_train_reshaped).reshape(X_train.shape)
X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape)

print(f"\nâœ“ Features normalized using StandardScaler")

# Convert to PyTorch tensors
X_train_tensor = torch.FloatTensor(X_train_scaled)
y_train_tensor = torch.LongTensor(y_train)
X_test_tensor = torch.FloatTensor(X_test_scaled)
y_test_tensor = torch.LongTensor(y_test)

# Create DataLoaders
BATCH_SIZE = 4
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
test_dataset = TensorDataset(X_test_tensor, y_test_tensor)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

print(f"\nDataLoaders created with batch size: {BATCH_SIZE}")
print(f"Train batches: {len(train_loader)}")
print(f"Test batches: {len(test_loader)}")

print(f"\nâœ“ Train-test split completed!")


# ============================================================================
# STEP 11: Build LSTM/GRU neural network for time-series shift prediction
# ============================================================================
print("\n" + "="*80)
print("STEP 11: Building LSTM/GRU Neural Network")
print("="*80)

class SentimentShiftPredictor(nn.Module):
    """
    LSTM-based neural network for sentiment shift prediction
    """
    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.3):
        super(SentimentShiftPredictor, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTM layer
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        # Dropout layer
        self.dropout = nn.Dropout(dropout)
        
        # Fully connected layers
        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size // 2, num_classes)
        
    def forward(self, x):
        # LSTM forward pass
        lstm_out, (hidden, cell) = self.lstm(x)
        
        # Use the last time step output
        last_output = lstm_out[:, -1, :]
        
        # Apply dropout
        out = self.dropout(last_output)
        
        # Fully connected layers
        out = self.fc1(out)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)
        
        return out

# Model hyperparameters
INPUT_SIZE = X_train.shape[2]  # Number of features
HIDDEN_SIZE = 64
NUM_LAYERS = 2
NUM_CLASSES = len(np.unique(y))
DROPOUT = 0.3

# Initialize model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SentimentShiftPredictor(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES, DROPOUT).to(device)

print(f"\n--- Model Architecture ---")
print(model)
print(f"\nDevice: {device}")
print(f"Total parameters: {sum(p.numel() for p in model.parameters())}")

print(f"\nâœ“ Neural network built successfully!")


# ============================================================================
# STEP 12: Apply hyperparameter tuning
# ============================================================================
print("\n" + "="*80)
print("STEP 12: Hyperparameter Configuration")
print("="*80)

# Hyperparameters
LEARNING_RATE = 0.0001
EPOCHS = 50
PATIENCE = 10  # For early stopping

print(f"\n--- Hyperparameters ---")
print(f"Learning Rate: {LEARNING_RATE}")
print(f"Hidden Size: {HIDDEN_SIZE}")
print(f"Number of LSTM Layers: {NUM_LAYERS}")
print(f"Dropout Rate: {DROPOUT}")
print(f"Batch Size: {BATCH_SIZE}")
print(f"Max Epochs: {EPOCHS}")
print(f"Early Stopping Patience: {PATIENCE}")

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)

print(f"\nâœ“ Hyperparameters configured!")


# ============================================================================
# STEP 13: Train the model
# ============================================================================
print("\n" + "="*80)
print("STEP 13: Training the Model")
print("="*80)

def train_model(model, train_loader, criterion, optimizer, device):
    """Train for one epoch"""
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for batch_X, batch_y in train_loader:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        
        # Forward pass
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        
        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        
        # Calculate accuracy
        _, predicted = torch.max(outputs.data, 1)
        total += batch_y.size(0)
        correct += (predicted == batch_y).sum().item()
        total_loss += loss.item()
    
    avg_loss = total_loss / len(train_loader)
    accuracy = 100 * correct / total
    
    return avg_loss, accuracy

def validate_model(model, test_loader, criterion, device):
    """Validate the model"""
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for batch_X, batch_y in test_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            
            _, predicted = torch.max(outputs.data, 1)
            total += batch_y.size(0)
            correct += (predicted == batch_y).sum().item()
            total_loss += loss.item()
    
    avg_loss = total_loss / len(test_loader)
    accuracy = 100 * correct / total
    
    return avg_loss, accuracy

# Training loop
train_losses, train_accuracies = [], []
val_losses, val_accuracies = [], []
best_val_loss = float('inf')
best_model_state = None
epochs_no_improve = 0

print("\nStarting training...")
print("-" * 70)

for epoch in range(EPOCHS):
    # Train
    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_acc)
    
    # Validate
    val_loss, val_acc = validate_model(model, test_loader, criterion, device)
    val_losses.append(val_loss)
    val_accuracies.append(val_acc)
    
    # Learning rate scheduling
    scheduler.step(val_loss)
    
    # Print progress
    if (epoch + 1) % 5 == 0 or epoch == 0:
        print(f"Epoch [{epoch+1}/{EPOCHS}] | "
              f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | "
              f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
    
    # Early stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_model_state = model.state_dict().copy()
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1
        
    if epochs_no_improve >= PATIENCE:
        print(f"\nEarly stopping triggered at epoch {epoch+1}")
        break

# Load best model
if best_model_state is not None:
    model.load_state_dict(best_model_state)
else:
    print("Warning: No best model state saved. Using current model state.")

print("-" * 70)
print(f"\nâœ“ Training completed!")
print(f"Best validation loss: {best_val_loss:.4f}")

# Plot training history
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Train Loss', linewidth=2)
plt.plot(val_losses, label='Validation Loss', linewidth=2)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Train Accuracy', linewidth=2)
plt.plot(val_accuracies, label='Validation Accuracy', linewidth=2)
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('training_history.png', dpi=150, bbox_inches='tight')
plt.show()


# ============================================================================
# STEP 14: Make predictions on test data
# ============================================================================
print("\n" + "="*80)
print("STEP 14: Making Predictions")
print("="*80)

model.eval()
all_predictions = []
all_probabilities = []

with torch.no_grad():
    for batch_X, _ in test_loader:
        batch_X = batch_X.to(device)
        outputs = model(batch_X)
        probabilities = torch.softmax(outputs, dim=1)
        _, predicted = torch.max(outputs, 1)
        
        all_predictions.extend(predicted.cpu().numpy())
        all_probabilities.extend(probabilities.cpu().numpy())

all_predictions = np.array(all_predictions)
all_probabilities = np.array(all_probabilities)

print(f"\nâœ“ Predictions completed for {len(all_predictions)} test samples")


# ============================================================================
# STEP 15: Evaluate model
# ============================================================================
print("\n" + "="*80)
print("STEP 15: Model Evaluation")
print("="*80)

# Calculate metrics
accuracy = accuracy_score(y_test, all_predictions)
f1 = f1_score(y_test, all_predictions, average='weighted')
precision, recall, f1_per_class, support = precision_recall_fscore_support(y_test, all_predictions)

print(f"\n--- Overall Metrics ---")
print(f"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"Weighted F1-Score: {f1:.4f}")

print(f"\n--- Per-Class Metrics ---")
for i, label in enumerate(label_encoder.classes_):
    print(f"{label:20s} - Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1_per_class[i]:.4f}, Support: {support[i]}")

# Classification report
print(f"\n--- Detailed Classification Report ---")
print(classification_report(y_test, all_predictions, target_names=label_encoder.classes_))

# Confusion matrix
cm = confusion_matrix(y_test, all_predictions)
print(f"\n--- Confusion Matrix ---")
print(cm)

# Visualize confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=label_encoder.classes_, 
            yticklabels=label_encoder.classes_,
            cbar_kws={'label': 'Count'})
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - Sentiment Shift Prediction')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"\nâœ“ Model evaluation completed!")


# ============================================================================
# STEP 16: Plot actual vs predicted sentiment trend
# ============================================================================
print("\n" + "="*80)
print("STEP 16: Actual vs Predicted Visualization")
print("="*80)

# Decode predictions
y_test_decoded = label_encoder.inverse_transform(y_test)
predictions_decoded = label_encoder.inverse_transform(all_predictions)

# Create comparison dataframe
comparison_df = pd.DataFrame({
    'Index': range(len(y_test)),
    'Actual': y_test_decoded,
    'Predicted': predictions_decoded,
    'Match': y_test == all_predictions
})

print(f"\n--- Prediction Accuracy by Class ---")
for label in label_encoder.classes_:
    mask = comparison_df['Actual'] == label
    if mask.sum() > 0:
        acc = comparison_df[mask]['Match'].mean() * 100
        print(f"{label:20s}: {acc:.2f}%")

# Visualize predictions
plt.figure(figsize=(15, 8))

plt.subplot(2, 1, 1)
# Convert labels to numeric for plotting
label_to_num = {'negative_shift': -1, 'stable': 0, 'positive_shift': 1}
actual_numeric = [label_to_num[label] for label in y_test_decoded]
predicted_numeric = [label_to_num[label] for label in predictions_decoded]

plt.plot(comparison_df['Index'], actual_numeric, 'o-', label='Actual', alpha=0.7, markersize=8)
plt.plot(comparison_df['Index'], predicted_numeric, 's--', label='Predicted', alpha=0.7, markersize=6)
plt.xlabel('Test Sample Index')
plt.ylabel('Shift Direction')
plt.yticks([-1, 0, 1], ['Negative', 'Stable', 'Positive'])
plt.title('Actual vs Predicted Sentiment Shifts')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(2, 1, 2)
colors = ['red' if not match else 'green' for match in comparison_df['Match']]
plt.scatter(comparison_df['Index'], actual_numeric, c=colors, alpha=0.6, s=100)
plt.xlabel('Test Sample Index')
plt.ylabel('Actual Shift Direction')
plt.yticks([-1, 0, 1], ['Negative', 'Stable', 'Positive'])
plt.title('Prediction Correctness (Green=Correct, Red=Incorrect)')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('actual_vs_predicted.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"\nâœ“ Visualization completed!")


# ============================================================================
# STEP 17: Plot shift probability distribution
# ============================================================================
print("\n" + "="*80)
print("STEP 17: Shift Probability Distribution")
print("="*80)

# Calculate average probabilities per class
avg_probs = np.mean(all_probabilities, axis=0)

print(f"\n--- Average Prediction Probabilities ---")
for i, label in enumerate(label_encoder.classes_):
    print(f"{label:20s}: {avg_probs[i]:.4f} ({avg_probs[i]*100:.2f}%)")

# Visualize probability distributions
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. Average probabilities by class
ax1 = axes[0, 0]
bars = ax1.bar(label_encoder.classes_, avg_probs, color=['red', 'gray', 'green'])
ax1.set_xlabel('Shift Class')
ax1.set_ylabel('Average Probability')
ax1.set_title('Average Prediction Probability by Class')
ax1.set_ylim([0, 1])
for bar, prob in zip(bars, avg_probs):
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height,
            f'{prob:.3f}', ha='center', va='bottom')

# 2. Probability distribution for each class
ax2 = axes[0, 1]
for i, label in enumerate(label_encoder.classes_):
    ax2.hist(all_probabilities[:, i], bins=20, alpha=0.5, label=label, edgecolor='black')
ax2.set_xlabel('Probability')
ax2.set_ylabel('Frequency')
ax2.set_title('Distribution of Prediction Probabilities')
ax2.legend()

# 3. Confidence distribution (max probability)
ax3 = axes[1, 0]
max_probs = np.max(all_probabilities, axis=1)
ax3.hist(max_probs, bins=20, color='skyblue', edgecolor='black')
ax3.axvline(max_probs.mean(), color='red', linestyle='--', linewidth=2, 
           label=f'Mean: {max_probs.mean():.3f}')
ax3.set_xlabel('Confidence (Max Probability)')
ax3.set_ylabel('Frequency')
ax3.set_title('Model Confidence Distribution')
ax3.legend()

# 4. Probability heatmap for sample predictions
ax4 = axes[1, 1]
sample_size = min(20, len(all_probabilities))
sample_probs = all_probabilities[:sample_size]
im = ax4.imshow(sample_probs.T, cmap='YlOrRd', aspect='auto')
ax4.set_xlabel('Test Sample')
ax4.set_ylabel('Shift Class')
ax4.set_yticks(range(len(label_encoder.classes_)))
ax4.set_yticklabels(label_encoder.classes_)
ax4.set_title(f'Probability Heatmap (First {sample_size} Samples)')
plt.colorbar(im, ax=ax4, label='Probability')

plt.tight_layout()
plt.savefig('probability_distribution.png', dpi=150, bbox_inches='tight')
plt.show()

# Additional statistics
print(f"\n--- Confidence Statistics ---")
print(f"Mean Confidence: {max_probs.mean():.4f}")
print(f"Median Confidence: {np.median(max_probs):.4f}")
print(f"Min Confidence: {max_probs.min():.4f}")
print(f"Max Confidence: {max_probs.max():.4f}")
print(f"Std Confidence: {max_probs.std():.4f}")

high_confidence = (max_probs > 0.8).sum()
low_confidence = (max_probs < 0.5).sum()
print(f"\nHigh confidence predictions (>0.8): {high_confidence} ({high_confidence/len(max_probs)*100:.2f}%)")
print(f"Low confidence predictions (<0.5): {low_confidence} ({low_confidence/len(max_probs)*100:.2f}%)")

print(f"\nâœ“ Probability analysis completed!")


# ============================================================================
# STEP 18: Save best performing model
# ============================================================================
print("\n" + "="*80)
print("STEP 18: Saving Model and Artifacts")
print("="*80)

# Create directory for saving
os.makedirs('model_artifacts', exist_ok=True)

# Save model
model_path = 'model_artifacts/sentiment_shift_model.pth'
torch.save({
    'model_state_dict': model.state_dict(),
    'input_size': INPUT_SIZE,
    'hidden_size': HIDDEN_SIZE,
    'num_layers': NUM_LAYERS,
    'num_classes': NUM_CLASSES,
    'dropout': DROPOUT,
    'sequence_length': SEQUENCE_LENGTH,
    'feature_columns': feature_columns,
    'best_val_loss': best_val_loss,
    'accuracy': accuracy,
    'f1_score': f1
}, model_path)

print(f"âœ“ Model saved to: {model_path}")

# Save scaler
scaler_path = 'model_artifacts/scaler.pkl'
with open(scaler_path, 'wb') as f:
    pickle.dump(scaler, f)
print(f"âœ“ Scaler saved to: {scaler_path}")

# Save label encoder
encoder_path = 'model_artifacts/label_encoder.pkl'
with open(encoder_path, 'wb') as f:
    pickle.dump(label_encoder, f)
print(f"âœ“ Label encoder saved to: {encoder_path}")

# Save metadata
metadata = {
    'accuracy': float(accuracy),
    'f1_score': float(f1),
    'best_val_loss': float(best_val_loss),
    'feature_columns': feature_columns,
    'sequence_length': SEQUENCE_LENGTH,
    'classes': label_encoder.classes_.tolist(),
    'training_samples': len(X_train),
    'test_samples': len(X_test)
}

metadata_path = 'model_artifacts/metadata.json'
with open(metadata_path, 'w') as f:
    json.dump(metadata, f, indent=4)
print(f"âœ“ Metadata saved to: {metadata_path}")

print(f"\nâœ“ All artifacts saved successfully!")


# ============================================================================
# STEP 19: Deploy prediction system using Gradio interface
# ============================================================================
print("\n" + "="*80)
print("STEP 19: Building Gradio Interface")
print("="*80)

class PredictionSystem:
    """Wrapper class for the prediction system"""
    
    def __init__(self, model, scaler, label_encoder, time_series_df, feature_columns, sequence_length):
        self.model = model
        self.scaler = scaler
        self.label_encoder = label_encoder
        self.time_series_df = time_series_df
        self.feature_columns = feature_columns
        self.sequence_length = sequence_length
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.model.eval()
    
    def predict_sentiment_shift(self, topic, forecast_horizon):
        """
        Predict sentiment shift for a given topic and forecast horizon
        
        Parameters:
        - topic: Political topic/tag (for demo, we'll use recent data)
        - forecast_horizon: Days to forecast (1-7)
        """
        try:
            # Validate forecast_horizon
            if pd.isna(forecast_horizon) or forecast_horizon is None:
                forecast_horizon = 3
            forecast_horizon = int(forecast_horizon)
            
            # Get recent data
            recent_data = self.time_series_df.tail(self.sequence_length + forecast_horizon)
            
            # Prepare sequence
            X_recent = recent_data[self.feature_columns].values[-self.sequence_length:]
            X_recent = X_recent.reshape(1, self.sequence_length, -1)
            
            # Scale
            X_recent_scaled = self.scaler.transform(
                X_recent.reshape(-1, X_recent.shape[-1])
            ).reshape(X_recent.shape)
            
            # Convert to tensor
            X_tensor = torch.FloatTensor(X_recent_scaled).to(self.device)
            
            # Predict
            with torch.no_grad():
                output = self.model(X_tensor)
                probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]
                prediction = np.argmax(probabilities)
            
            # Decode prediction
            predicted_label = self.label_encoder.inverse_transform([prediction])[0]
            
            # Create results dictionary
            results = {
                'prediction': predicted_label,
                'probabilities': {
                    label: float(prob) 
                    for label, prob in zip(self.label_encoder.classes_, probabilities)
                },
                'confidence': float(np.max(probabilities)),
                'forecast_horizon': forecast_horizon
            }
            
            # Generate forecast visualization
            fig = self.create_forecast_plot(recent_data, predicted_label, probabilities, forecast_horizon)
            
            # Generate probability chart
            prob_fig = self.create_probability_chart(probabilities)
            
            # Create summary text
            summary = self.generate_summary(results, topic)
            
            return summary, fig, prob_fig
            
        except Exception as e:
            return f"Error in prediction: {str(e)}", None, None
    
    def create_forecast_plot(self, recent_data, predicted_label, probabilities, forecast_horizon):
        """Create forecast visualization"""
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # Plot 1: Historical sentiment trend
        dates = recent_data['date'].values
        sentiment = recent_data['sentiment_mean'].values
        
        ax1.plot(dates, sentiment, marker='o', linewidth=2, markersize=6, label='Historical Sentiment')
        ax1.axhline(0, color='red', linestyle='--', linewidth=1, alpha=0.5)
        ax1.fill_between(dates, 
                        recent_data['sentiment_mean'] - recent_data['sentiment_std'],
                        recent_data['sentiment_mean'] + recent_data['sentiment_std'],
                        alpha=0.3, label='Â±1 Std Dev')
        
        # Add forecast indication
        last_date = dates[-1]
        last_sentiment = sentiment[-1]
        
        # Estimate future sentiment based on prediction
        shift_direction = {'positive_shift': 0.2, 'stable': 0, 'negative_shift': -0.2}
        future_sentiment = last_sentiment + shift_direction.get(predicted_label, 0)
        
        forecast_dates = pd.date_range(start=last_date, periods=forecast_horizon+1, freq='D')[1:]
        forecast_sentiments = np.linspace(last_sentiment, future_sentiment, forecast_horizon)
        
        ax1.plot(forecast_dates, forecast_sentiments, 'r--', linewidth=2, 
                marker='s', markersize=6, label=f'Forecast ({predicted_label})')
        
        ax1.set_xlabel('Date', fontsize=11)
        ax1.set_ylabel('Sentiment Score', fontsize=11)
        ax1.set_title('Political Sentiment Trend and Forecast', fontsize=13, fontweight='bold')
        ax1.legend(fontsize=10)
        ax1.grid(True, alpha=0.3)
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # Plot 2: Shift indicators
        shift_colors = {'negative_shift': 'red', 'stable': 'gray', 'positive_shift': 'green'}
        
        for i, date in enumerate(dates[-5:]):
            color = shift_colors.get(predicted_label if i == len(dates[-5:])-1 else 'stable', 'blue')
            ax2.bar(i, sentiment[-5:][i], color=color, alpha=0.7, edgecolor='black')
        
        ax2.axhline(0, color='red', linestyle='--', linewidth=1)
        ax2.set_xlabel('Recent Time Steps', fontsize=11)
        ax2.set_ylabel('Sentiment Score', fontsize=11)
        ax2.set_title('Recent Sentiment Pattern', fontsize=13, fontweight='bold')
        ax2.set_xticks(range(5))
        ax2.set_xticklabels([f'T-{4-i}' for i in range(5)])
        ax2.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        return fig
    
    def create_probability_chart(self, probabilities):
        """Create probability distribution chart"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
        # Bar chart
        colors = ['red', 'gray', 'green']
        bars = ax1.bar(self.label_encoder.classes_, probabilities, color=colors, alpha=0.7, edgecolor='black')
        ax1.set_ylabel('Probability', fontsize=11)
        ax1.set_title('Shift Probability Distribution', fontsize=13, fontweight='bold')
        ax1.set_ylim([0, 1])
        
        for bar, prob in zip(bars, probabilities):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{prob:.2%}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # Pie chart
        ax2.pie(probabilities, labels=self.label_encoder.classes_, autopct='%1.1f%%',
               colors=colors, startangle=90, explode=[0.05, 0, 0.05])
        ax2.set_title('Shift Probability Breakdown', fontsize=13, fontweight='bold')
        
        plt.tight_layout()
        return fig
    
    def generate_summary(self, results, topic):
        """Generate prediction summary"""
        prediction = results['prediction']
        confidence = results['confidence']
        probabilities = results['probabilities']
        horizon = results['forecast_horizon']
        
        summary = f"""
ðŸ“Š **POLITICAL SENTIMENT SHIFT PREDICTION**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ðŸŽ¯ **Topic:** {topic}
ðŸ“… **Forecast Horizon:** {horizon} days

**ðŸ”® PREDICTION RESULTS:**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Predicted Shift:** {prediction.upper().replace('_', ' ')}
**Confidence:** {confidence:.2%}

**ðŸ“ˆ Probability Breakdown:**
â€¢ Positive Shift: {probabilities['positive_shift']:.2%}
â€¢ Stable: {probabilities['stable']:.2%}
â€¢ Negative Shift: {probabilities['negative_shift']:.2%}

**ðŸ’¡ INTERPRETATION:**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
        
        if prediction == 'positive_shift':
            summary += """
âœ… The model predicts a **POSITIVE sentiment shift** in political discourse.
   This suggests:
   â€¢ Increasing public approval or positive sentiment
   â€¢ Favorable news coverage or policy developments
   â€¢ Potential improvement in political climate
"""
        elif prediction == 'negative_shift':
            summary += """
âš ï¸ The model predicts a **NEGATIVE sentiment shift** in political discourse.
   This suggests:
   â€¢ Decreasing public approval or negative sentiment
   â€¢ Unfavorable news coverage or controversies
   â€¢ Potential deterioration in political climate
"""
        else:
            summary += """
âž¡ï¸ The model predicts **STABLE sentiment** in political discourse.
   This suggests:
   â€¢ Maintaining current sentiment levels
   â€¢ Balanced news coverage
   â€¢ Steady political climate with no major shifts
"""
        
        if confidence > 0.7:
            summary += f"\nðŸŽ¯ **High confidence** ({confidence:.2%}) - The prediction is reliable."
        elif confidence > 0.5:
            summary += f"\nâš¡ **Moderate confidence** ({confidence:.2%}) - The prediction has some uncertainty."
        else:
            summary += f"\nâš ï¸ **Low confidence** ({confidence:.2%}) - The prediction is highly uncertain."
        
        summary += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        
        return summary

# Initialize prediction system
prediction_system = PredictionSystem(
    model=model,
    scaler=scaler,
    label_encoder=label_encoder,
    time_series_df=time_series_df,
    feature_columns=feature_columns,
    sequence_length=SEQUENCE_LENGTH
)

# Create Gradio interface
def gradio_predict(topic, forecast_horizon):
    """Gradio wrapper function"""
    return prediction_system.predict_sentiment_shift(topic, forecast_horizon)

# Define interface
iface = gr.Interface(
    fn=gradio_predict,
    inputs=[
        gr.Dropdown(
            choices=['General Politics', 'Elections', 'Government Policy', 
                    'International Relations', 'Social Issues', 'Economic Policy'],
            value='General Politics',
            label="ðŸ“Œ Select Political Topic"
        ),
        gr.Slider(
            minimum=1,
            maximum=7,
            value=3,
            step=1,
            label="ðŸ“… Forecast Horizon (Days)"
        )
    ],
    outputs=[
        gr.Textbox(label="ðŸ“Š Prediction Summary", lines=25),
        gr.Plot(label="ðŸ“ˆ Sentiment Trend and Forecast"),
        gr.Plot(label="ðŸ“Š Probability Distribution")
    ],
    title="ðŸ›ï¸ Political Sentiment Shift Prediction System",
    description="""
    **AI-Powered Political Sentiment Analysis and Forecasting**
    
    This system uses LSTM neural networks to predict sentiment shifts in political discourse.
    Select a topic and forecast horizon to get predictions with confidence scores and visualizations.
    
    ðŸ” **Model Performance:** Accuracy = {:.2%} | F1-Score = {:.4f}
    """.format(accuracy, f1),
    theme=gr.themes.Soft(),
    examples=[
        ['General Politics', 3],
        ['Elections', 5],
        ['Government Policy', 7]
    ]
)

print("\nâœ“ Gradio interface created successfully!")
print("\nLaunching interface...")


# ============================================================================
# STEP 20: Launch Gradio interface
# ============================================================================
print("\n" + "="*80)
print("STEP 20: Deploying Prediction System")
print("="*80)

# Launch the interface
print("\nðŸš€ Launching Gradio Interface...")
print("="*80)

# For Colab, use share=True to get public URL
iface.launch(share=True, debug=True)

print("\n" + "="*80)
print("âœ… ALL 20 STEPS COMPLETED SUCCESSFULLY!")
print("="*80)

# Final summary
print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ðŸŽ‰ PROJECT SUMMARY ðŸŽ‰                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                           â•‘
â•‘  âœ… Dataset loaded and explored: {df.shape[0]} articles                              â•‘
â•‘  âœ… Text preprocessing completed                                         â•‘
â•‘  âœ… Sentiment analysis using DistilBERT                                  â•‘
â•‘  âœ… Time-series dataset created: {time_series_df.shape[0]} time points                   â•‘
â•‘  âœ… LSTM neural network trained                                          â•‘
â•‘  âœ… Model accuracy: {accuracy:.2%}                                              â•‘
â•‘  âœ… F1-Score: {f1:.4f}                                                     â•‘
â•‘  âœ… Model saved to: model_artifacts/                                     â•‘
â•‘  âœ… Gradio interface deployed                                            â•‘
â•‘                                                                           â•‘
â•‘  ðŸ“Š Model can now predict sentiment shifts in political discourse!       â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“ Generated Files:
   â€¢ model_artifacts/sentiment_shift_model.pth
   â€¢ model_artifacts/scaler.pkl
   â€¢ model_artifacts/label_encoder.pkl
   â€¢ model_artifacts/metadata.json
   â€¢ content_length_analysis.png
   â€¢ sentiment_distribution.png
   â€¢ time_series_sentiment.png
   â€¢ shift_labels.png
   â€¢ training_history.png
   â€¢ confusion_matrix.png
   â€¢ actual_vs_predicted.png
   â€¢ probability_distribution.png

ðŸŽ¯ Next Steps:
   1. Use the Gradio interface to make predictions
   2. Collect more data for better accuracy
   3. Fine-tune hyperparameters
   4. Deploy to production environment
   5. Set up monitoring and retraining pipeline

ðŸ™ Thank you for using the Political Sentiment Shift Prediction System!
""")
